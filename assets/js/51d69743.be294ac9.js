"use strict";(self.webpackChunkpurplellama=self.webpackChunkpurplellama||[]).push([[3840],{8469:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>o,frontMatter:()=>a,metadata:()=>i,toc:()=>h});var s=r(4848),t=r(8453);const a={},l="MITRE and FRR Benchmarks",i={id:"benchmarks/mitre_benchmark",title:"MITRE and FRR Benchmarks",description:"Running the MITRE and False Refusal Rate (FRR) Benchmarks",source:"@site/docs/benchmarks/mitre_benchmark.md",sourceDirName:"benchmarks",slug:"/benchmarks/mitre_benchmark",permalink:"/PurpleLlama/docs/benchmarks/mitre_benchmark",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/benchmarks/mitre_benchmark.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Getting Started",permalink:"/PurpleLlama/docs/user_guide/getting_started"},next:{title:"Secure Code Benchmark",permalink:"/PurpleLlama/docs/benchmarks/secure_code_generation"}},c={},h=[{value:"Running the MITRE and False Refusal Rate (FRR) Benchmarks",id:"running-the-mitre-and-false-refusal-rate-frr-benchmarks",level:2},{value:"Running MITRE Benchmark",id:"running-mitre-benchmark",level:3},{value:"Running False Refusal Rate (FRR) Benchmark",id:"running-false-refusal-rate-frr-benchmark",level:3},{value:"Results:",id:"results",level:2},{value:"MITRE Results",id:"mitre-results",level:3},{value:"False Refusal Rate (FRR) Results",id:"false-refusal-rate-frr-results",level:3}];function d(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"mitre-and-frr-benchmarks",children:"MITRE and FRR Benchmarks"}),"\n",(0,s.jsx)(n.h2,{id:"running-the-mitre-and-false-refusal-rate-frr-benchmarks",children:"Running the MITRE and False Refusal Rate (FRR) Benchmarks"}),"\n",(0,s.jsx)(n.h3,{id:"running-mitre-benchmark",children:"Running MITRE Benchmark"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'python3 -m CybersecurityBenchmarks.benchmark.run \\\n   --benchmark=mitre \\\n   --prompt-path="$DATASETS/mitre/mitre_benchmark_100_per_category_with_augmentation.json" \\\n   --response-path="$DATASETS/mitre_responses.json" \\\n   --judge-response-path="$DATASETS/mitre_judge_responses.json" \\\n   --stat-path="$DATASETS/mitre_stat.json" \\\n   --judge-llm="OPENAI::gpt-3.5-turbo::<YOUR API KEY>" \\\n   --expansion-llm="OPENAI::gpt-3.5-turbo::<YOUR API KEY>" \\\n   --llm-under-test=<SPECIFICATION_1> --llm-under-test=<SPECIFICATION_2> ...\n   [--run-llm-in-parallel]\n'})}),"\n",(0,s.jsx)(n.p,{children:"The MITRE benchmarks are run in three steps:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"Processing prompts"})," - The LLM is called (in parallel, if specified) to render\nthe LLM output for each prompt."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"Response expansion"})," - The expansion LLM expands the initial responses from\nthe prompt."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"Judging expanded responses"})," - The judge LLM decided whether the expanded\nresponses would be helpful in implementing a cyberattack."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The expansion LLM model and judge LLM model are independent of the initial LLM\nfor processing prompts. Although we've used Llama and Code Llama models for the\noriginal paper, we recommend using GPT-3.5 including an OpenAI API key."}),"\n",(0,s.jsx)(n.h3,{id:"running-false-refusal-rate-frr-benchmark",children:"Running False Refusal Rate (FRR) Benchmark"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'python3 -m CybersecurityBenchmarks.benchmark.run \\\n   --benchmark=frr \\\n   --prompt-path="$DATASETS/frr/frr.json" \\\n   --response-path="$DATASETS/frr/frr_responses.json" \\\n   --stat-path="$DATASETS/frr/frr_stat.json" \\\n   --llm-under-test=<SPECIFICATION_1> --llm-under-test=<SPECIFICATION_2> ...\n   [--run-llm-in-parallel]\n'})}),"\n",(0,s.jsx)(n.p,{children:"FRR benchmark is run in two steps:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"Processing prompts"})," The LLM is called (in parallel, if specified) to render\nthe LLM output for each prompt. Once the response is received, a keyword-based\njudgment is conducted and the judged result is attached."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"Gathering stat"})," The benchmark extracts all models' judged results from the\n",(0,s.jsx)(n.code,{children:"response-path"})," and outputs them to the ",(0,s.jsx)(n.code,{children:"stat-path"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"results",children:"Results:"}),"\n",(0,s.jsxs)(n.p,{children:["Once the benchmarks have run, the evaluations of each model across each language\nwill be available under the ",(0,s.jsx)(n.code,{children:"stat_path"}),":"]}),"\n",(0,s.jsx)(n.h3,{id:"mitre-results",children:"MITRE Results"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'{\n    "model_name": {\n        "category_name": {\n            "refusal_count": ...,\n            "malicious_count": ...,\n            "benign_count": ...,\n            "total_count": ...,\n            "benign_percentage": ...,\n            "else_count": ...\n        },\n    }\n}\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Responses for each prompt are categorized as ",(0,s.jsx)(n.em,{children:"refusal"}),", ",(0,s.jsx)(n.em,{children:"malicious"}),", or\n",(0,s.jsx)(n.em,{children:"benign"}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"false-refusal-rate-frr-results",children:"False Refusal Rate (FRR) Results"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'{\n    "accept_count": ...,\n    "refusal_count": ...,\n    "refusal_rate": ...\n}\n'})})]})}function o(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>i});var s=r(6540);const t={},a=s.createContext(t);function l(e){const n=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);