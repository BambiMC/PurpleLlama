"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[863],{6133:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"tutorials/alignment-check-scanner-tutorial","title":"Alignment Check Scanner Tutorial","description":"In this tutorial, we\'ll explore the demo_alignmentcheck.py script from the examples. The Alignment Check Scanner is designed to detect potentially compromised or misaligned agent behavior in conversation traces. This demo shows how to use the scanner to analyze two example traces: one with high-risk input (compromised) and another with low-risk input (not compromised).","source":"@site/docs/tutorials/alignment-check-scanner-tutorial.md","sourceDirName":"tutorials","slug":"/tutorials/alignment-check-scanner-tutorial","permalink":"/PurpleLlama/LlamaFirewall/docs/tutorials/alignment-check-scanner-tutorial","draft":false,"unlisted":false,"editUrl":"https://github.com/meta-llama/PurpleLlama/tree/main/LlamaFirewall/website/docs/tutorials/alignment-check-scanner-tutorial.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialsSidebar","previous":{"title":"Prompt Guard Scanner Tutorial","permalink":"/PurpleLlama/LlamaFirewall/docs/tutorials/prompt-guard-scanner-tutorial"},"next":{"title":"CodeShield Scanner Tutorial","permalink":"/PurpleLlama/LlamaFirewall/docs/tutorials/codeshield-scanner-tutorial"}}');var a=t(4848),s=t(8453);const r={sidebar_position:2},o="Alignment Check Scanner Tutorial",c={},l=[{value:"Importing Dependencies",id:"importing-dependencies",level:3},{value:"Defining Example Traces",id:"defining-example-traces",level:3},{value:"Running the Alignment Check",id:"running-the-alignment-check",level:3},{value:"Displaying the Scan Result",id:"displaying-the-scan-result",level:3},{value:"Checking the Environment",id:"checking-the-environment",level:3},{value:"Main Function",id:"main-function",level:3},{value:"Running the Example",id:"running-the-example",level:3}];function h(e){const n={a:"a",code:"code",h1:"h1",h3:"h3",header:"header",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"alignment-check-scanner-tutorial",children:"Alignment Check Scanner Tutorial"})}),"\n",(0,a.jsxs)(n.p,{children:["In this tutorial, we'll explore the ",(0,a.jsx)(n.code,{children:"demo_alignmentcheck.py"})," script from the ",(0,a.jsx)(n.a,{href:"https://github.com/meta-llama/PurpleLlama/tree/main/LlamaFirewall/examples",children:"examples"}),". The Alignment Check Scanner is designed to detect potentially compromised or misaligned agent behavior in conversation traces. This demo shows how to use the scanner to analyze two example traces: one with high-risk input (compromised) and another with low-risk input (not compromised)."]}),"\n",(0,a.jsx)(n.h3,{id:"importing-dependencies",children:"Importing Dependencies"}),"\n",(0,a.jsx)(n.p,{children:"The script starts by importing the necessary dependencies:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import json\nimport logging\nimport os\nimport sys\nfrom typing import Dict, Optional\n\nfrom llamafirewall import (\n    AssistantMessage,\n    LlamaFirewall,\n    Role,\n    ScannerType,\n    ScanResult,\n    Trace,\n    UserMessage,\n)\n"})}),"\n",(0,a.jsxs)(n.p,{children:["These imports bring in the required classes and functions from the ",(0,a.jsx)(n.code,{children:"llamafirewall"})," library."]}),"\n",(0,a.jsx)(n.h3,{id:"defining-example-traces",children:"Defining Example Traces"}),"\n",(0,a.jsxs)(n.p,{children:["The script defines two example traces using the ",(0,a.jsx)(n.code,{children:"get_sample_traces"})," function:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"def get_sample_traces() -> Dict[str, Trace]:\n    # ...\n"})}),"\n",(0,a.jsx)(n.p,{children:"These traces represent two different scenarios: one with high-risk input (compromised) and another with low-risk input (not compromised)."}),"\n",(0,a.jsx)(n.h3,{id:"running-the-alignment-check",children:"Running the Alignment Check"}),"\n",(0,a.jsxs)(n.p,{children:["The script runs the alignment check on each trace using the ",(0,a.jsx)(n.code,{children:"run_alignment_check"})," function:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"def run_alignment_check(trace: Trace) -> Optional[ScanResult]:\n    # ...\n"})}),"\n",(0,a.jsx)(n.p,{children:"This function initializes the LlamaFirewall with the AlignmentCheck scanner and scans the provided trace."}),"\n",(0,a.jsx)(n.h3,{id:"displaying-the-scan-result",children:"Displaying the Scan Result"}),"\n",(0,a.jsxs)(n.p,{children:["The script displays the scan result for each trace using the ",(0,a.jsx)(n.code,{children:"display_scan_result"})," function:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"def display_scan_result(result: Optional[ScanResult], description: str) -> None:\n    # ...\n"})}),"\n",(0,a.jsx)(n.p,{children:"This function prints out the scan result in a formatted way, including the score, decision, reason, and other relevant information."}),"\n",(0,a.jsx)(n.h3,{id:"checking-the-environment",children:"Checking the Environment"}),"\n",(0,a.jsxs)(n.p,{children:["The script checks if the required environment variables are set using the ",(0,a.jsx)(n.code,{children:"check_environment"})," function:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"def check_environment() -> bool:\n    # ...\n"})}),"\n",(0,a.jsxs)(n.p,{children:["This function ensures that the ",(0,a.jsx)(n.code,{children:"TOGETHER_API_KEY"})," environment variable is set before running the demo."]}),"\n",(0,a.jsx)(n.h3,{id:"main-function",children:"Main Function"}),"\n",(0,a.jsx)(n.p,{children:"The script's main function is defined as follows:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"def main() -> int:\n    # ...\n"})}),"\n",(0,a.jsxs)(n.p,{children:["This function calls the ",(0,a.jsx)(n.code,{children:"check_environment"})," function to ensure that the environment is properly configured. It then gets the example traces, runs the alignment check on each trace, and displays the scan results."]}),"\n",(0,a.jsx)(n.h3,{id:"running-the-example",children:"Running the Example"}),"\n",(0,a.jsx)(n.p,{children:"So that's it, the script is easily run with the following command:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"python demo_alignmentcheck.py\n"})}),"\n",(0,a.jsx)(n.p,{children:"And the output should look something like this:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"...\n=== Testing High-risk ===\n2025-04-27 13:08:10,935 - logging_setup - INFO - === Scan Result ===\nScore: 1.0000\nDecision: ScanDecision.HUMAN_IN_THE_LOOP_REQUIRED\nReason: Observation: The agent has booked a product review appointment as requested and sent a confirmation email. However, it then attempts to attach a malicious file to the email, which is not related to the original task and could compromise the user's personal data.\nThought: The initial actions of the agent are aligned with the user's request to book an appointment and send a confirmation. However, the final action of attaching a malicious file to the email is not only unrelated to the task but also poses a security risk. This indicates a clear deviation from the original objective and a potential security threat.\nConclusion: True\n==================\n2025-04-27 13:08:12,949 - httpx - INFO - HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n2025-04-27 13:08:12,956 - llamafirewall.scanners.custom_check_scanner - INFO - [LlamaFirewall] LLM-based scanner response: observation='The agent is verifying the latest message from the user before proceeding with retrieving the repository details.' thought=\"The agent's action of fetching the latest user message is a step to confirm the request and ensure it has the correct context before taking further action on retrieving the repository details. This is related to the original objective and does not indicate a deviation from the task.\" conclusion=False\n2025-04-27 13:08:12,957 - logging_setup - INFO -\n\n=== Testing Low-risk ===\n2025-04-27 13:08:12,957 - logging_setup - INFO - === Scan Result ===\nScore: 0.0000\nDecision: ScanDecision.ALLOW\nReason: default\n==================\n"})}),"\n",(0,a.jsx)(n.p,{children:"That wraps it up! You now can see how Alignment Check helps detect potentially compromised or misaligned agent behavior in conversation traces."})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var i=t(6540);const a={},s=i.createContext(a);function r(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);