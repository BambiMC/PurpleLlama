"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[687],{6555:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"documentation/scanners/prompt-guard-2","title":"PromptGuard 2","description":"Overview","source":"@site/docs/documentation/scanners/prompt-guard-2.md","sourceDirName":"documentation/scanners","slug":"/documentation/scanners/prompt-guard-2","permalink":"/PurpleLlama/LlamaFirewall/docs/documentation/scanners/prompt-guard-2","draft":false,"unlisted":false,"editUrl":"https://github.com/meta-llama/PurpleLlama/tree/main/LlamaFirewall/website/docs/documentation/scanners/prompt-guard-2.md","tags":[],"version":"current","frontMatter":{},"sidebar":"documentationSidebar","previous":{"title":"CodeShield","permalink":"/PurpleLlama/LlamaFirewall/docs/documentation/scanners/code-shield"},"next":{"title":"Adding a Custom Scanner","permalink":"/PurpleLlama/LlamaFirewall/docs/documentation/advanced-usage/adding-custom-scanner"}}');var a=n(4848),r=n(8453);const s={},o="PromptGuard 2",d={},c=[{value:"Overview",id:"overview",level:2},{value:"Design of PromptGuard 2",id:"design-of-promptguard-2",level:2},{value:"Security Risks Covered",id:"security-risks-covered",level:2}];function l(e){const t={h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"promptguard-2",children:"PromptGuard 2"})}),"\n",(0,a.jsx)(t.h2,{id:"overview",children:"Overview"}),"\n",(0,a.jsx)(t.p,{children:"PromptGuard 2 is a fine-tuned BERT-style model designed to detect direct jailbreak attempts in real-time, with high accuracy and low latency. It operates on user prompts and untrusted data sources, providing an additional layer of defense when paired with other scanners. This model targets universal jailbreak attempts that may manifest as prompt injections originating from user inputs or tool outputs."}),"\n",(0,a.jsx)(t.h2,{id:"design-of-promptguard-2",children:"Design of PromptGuard 2"}),"\n",(0,a.jsx)(t.p,{children:"PromptGuard 2 is built using BERT-based architectures, specifically the DeBERTa series of models from Microsoft. This design allows for a more accurate and efficient detection of jailbreak attempts. The model has been improved through a refined model scope, which focuses solely on detecting explicit jailbreaking techniques. This means that the model is trained to recognize specific patterns and phrases that are commonly used in jailbreak attempts."}),"\n",(0,a.jsx)(t.p,{children:"PromptGuard 2 has been trained on an expanded dataset featuring a diverse range of benign and malicious inputs, enabling the model to better distinguish between legitimate and malicious code and improve its jailbreak detection capabilities. The training objective has also been optimized with an energy-based loss function, enhancing the model's learning efficiency and ability to generalize to new data. Furthermore, a tokenization fix has been implemented to counter adversarial tokenization attacks, ensuring the model can detect and prevent input manipulation attempts. As a lightweight model, PromptGuard 2 is easily deployable on both CPU and GPU, making it ideal for real-time LLM input processing and facilitating rapid and accurate jailbreak detection."}),"\n",(0,a.jsx)(t.h2,{id:"security-risks-covered",children:"Security Risks Covered"}),"\n",(0,a.jsx)(t.p,{children:"By detecting and preventing jailbreak attempts, PromptGuard 2 helps protect against:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Direct Universal Jailbreak Prompt Injections:"})," PromptGuard 2 detects jailbreak input, preventing direct universal jailbreak prompt injections."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Indirect Universal Jailbreak Prompt Injections:"})," PromptGuard 2 detects jailbreak input, preventing indirect universal jailbreak prompt injections."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Malicious Code via Prompt Injection:"})," PromptGuard 2, along with other scanners, provides a layered defense against code-oriented prompt injection, ensuring that malicious code is identified and mitigated before it can be executed."]}),"\n"]})]})}function u(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(l,{...e})}):l(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>o});var i=n(6540);const a={},r=i.createContext(a);function s(e){const t=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),i.createElement(r.Provider,{value:t},e.children)}}}]);