"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[845],{6454:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"documentationSidebar":[{"type":"link","label":"About LlamaFirewall","href":"/PurpleLlama/LlamaFirewall/docs/documentation/about-llamafirewall","docId":"documentation/about-llamafirewall","unlisted":false},{"type":"category","label":"Getting Started","collapsible":true,"collapsed":false,"items":[{"type":"link","label":"How to use LlamaFirewall","href":"/PurpleLlama/LlamaFirewall/docs/documentation/getting-started/how-to-use-llamafirewall","docId":"documentation/getting-started/how-to-use-llamafirewall","unlisted":false},{"type":"link","label":"Adding a Custom Use Case","href":"/PurpleLlama/LlamaFirewall/docs/documentation/getting-started/adding-custom-use-case","docId":"documentation/getting-started/adding-custom-use-case","unlisted":false}]},{"type":"category","label":"Architecture","collapsible":true,"collapsed":false,"items":[{"type":"link","label":"LlamaFirewall Architecture","href":"/PurpleLlama/LlamaFirewall/docs/documentation/llamafirewall-architecture/architecture","docId":"documentation/llamafirewall-architecture/architecture","unlisted":false},{"type":"link","label":"LlamaFirewall Workflow and Detection Components","href":"/PurpleLlama/LlamaFirewall/docs/documentation/llamafirewall-architecture/workflow-and-detection-components","docId":"documentation/llamafirewall-architecture/workflow-and-detection-components","unlisted":false}]},{"type":"category","label":"Scanners","collapsible":true,"collapsed":false,"items":[{"type":"link","label":"AlignmentCheck","href":"/PurpleLlama/LlamaFirewall/docs/documentation/scanners/alignment-check","docId":"documentation/scanners/alignment-check","unlisted":false},{"type":"link","label":"CodeShield","href":"/PurpleLlama/LlamaFirewall/docs/documentation/scanners/code-shield","docId":"documentation/scanners/code-shield","unlisted":false},{"type":"link","label":"PromptGuard 2","href":"/PurpleLlama/LlamaFirewall/docs/documentation/scanners/prompt-guard-2","docId":"documentation/scanners/prompt-guard-2","unlisted":false}]},{"type":"category","label":"Advanced Usage","collapsible":true,"collapsed":false,"items":[{"type":"link","label":"Adding a Custom Scanner","href":"/PurpleLlama/LlamaFirewall/docs/documentation/advanced-usage/adding-custom-scanner","docId":"documentation/advanced-usage/adding-custom-scanner","unlisted":false}]}],"tutorialsSidebar":[{"type":"link","label":"Prompt Guard Scanner Tutorial","href":"/PurpleLlama/LlamaFirewall/docs/tutorials/prompt-guard-scanner-tutorial","docId":"tutorials/prompt-guard-scanner-tutorial","unlisted":false},{"type":"link","label":"Alignment Check Scanner Tutorial","href":"/PurpleLlama/LlamaFirewall/docs/tutorials/alignment-check-scanner-tutorial","docId":"tutorials/alignment-check-scanner-tutorial","unlisted":false},{"type":"link","label":"CodeShield Scanner Tutorial","href":"/PurpleLlama/LlamaFirewall/docs/tutorials/codeshield-scanner-tutorial","docId":"tutorials/codeshield-scanner-tutorial","unlisted":false},{"type":"link","label":"Prompt Regex Scanner Tutorial","href":"/PurpleLlama/LlamaFirewall/docs/tutorials/regex-scanner-tutorial","docId":"tutorials/regex-scanner-tutorial","unlisted":false},{"type":"link","label":"Notebook: Standalone Agent with LlamaFirewall","href":"/PurpleLlama/LlamaFirewall/docs/tutorials/standalone-agent-llamafirewall-tutorial","docId":"tutorials/standalone-agent-llamafirewall-tutorial","unlisted":false}],"demosSidebar":[{"type":"link","label":"LlamaFirewall Demos","href":"/PurpleLlama/LlamaFirewall/docs/demos/","docId":"demos/demos","unlisted":false}]},"docs":{"demos/demos":{"id":"demos/demos","title":"LlamaFirewall Demos","description":"Be witness to the power of LlamaFirewall in a couple real-world scenarios where protecting against harmful inputs and outputs is crucial.","sidebar":"demosSidebar"},"documentation/about-llamafirewall":{"id":"documentation/about-llamafirewall","title":"About LlamaFirewall","description":"LlamaFirewall is a framework designed to detect and mitigate AI centric security risks, supporting multiple layers of inputs and outputs, such as typical LLM chat and more advanced multi-step agentic operations. It consists of a set of scanners for different security risks.","sidebar":"documentationSidebar"},"documentation/advanced-usage/adding-custom-scanner":{"id":"documentation/advanced-usage/adding-custom-scanner","title":"Adding a Custom Scanner","description":"LlamaFirewall is a modular security system that allows developers to create custom scanners to detect and prevent specific types of threats. In this guide, we will walk you through the process of creating a new custom scanner for LlamaFirewall.","sidebar":"documentationSidebar"},"documentation/getting-started/adding-custom-use-case":{"id":"documentation/getting-started/adding-custom-use-case","title":"Adding a Custom Use Case","description":"Introduction to Use Cases","sidebar":"documentationSidebar"},"documentation/getting-started/how-to-use-llamafirewall":{"id":"documentation/getting-started/how-to-use-llamafirewall","title":"How to use LlamaFirewall","description":"Prerequisites","sidebar":"documentationSidebar"},"documentation/llamafirewall-architecture/architecture":{"id":"documentation/llamafirewall-architecture/architecture","title":"LlamaFirewall Architecture","description":"LlamaFirewall is built to serve as a flexible, real-time guardrail framework for securing LLM-powered applications. Its architecture is modular, enabling security teams and developers to compose layered defenses that span from raw input ingestion to final output actions\u2014across simple chat models and complex autonomous agents.","sidebar":"documentationSidebar"},"documentation/llamafirewall-architecture/workflow-and-detection-components":{"id":"documentation/llamafirewall-architecture/workflow-and-detection-components","title":"LlamaFirewall Workflow and Detection Components","description":"LlamaFirewall is an extensible AI guardrail framework designed to mitigate a wide spectrum of AI agent security risks, including direct and indirect jailbreaking, goal hijacking, insecure coding agent outputs, and malicious code injection via prompt injection.","sidebar":"documentationSidebar"},"documentation/scanners/alignment-check":{"id":"documentation/scanners/alignment-check","title":"AlignmentCheck","description":"Overview","sidebar":"documentationSidebar"},"documentation/scanners/code-shield":{"id":"documentation/scanners/code-shield","title":"CodeShield","description":"Overview","sidebar":"documentationSidebar"},"documentation/scanners/prompt-guard-2":{"id":"documentation/scanners/prompt-guard-2","title":"PromptGuard 2","description":"Overview","sidebar":"documentationSidebar"},"tutorials/alignment-check-scanner-tutorial":{"id":"tutorials/alignment-check-scanner-tutorial","title":"Alignment Check Scanner Tutorial","description":"In this tutorial, we\'ll explore the demo_alignmentcheck.py script from the examples. The Alignment Check Scanner is designed to detect potentially compromised or misaligned agent behavior in conversation traces. This demo shows how to use the scanner to analyze two example traces: one with high-risk input (compromised) and another with low-risk input (not compromised).","sidebar":"tutorialsSidebar"},"tutorials/codeshield-scanner-tutorial":{"id":"tutorials/codeshield-scanner-tutorial","title":"CodeShield Scanner Tutorial","description":"In this tutorial, we\'ll go through the democodeshieldscanner.py script from the examples and learn how to use the CodeShield scanner in LlamaFirewall. This scanner is designed to detect potentially insecure code from a given input text. This script demonstrates how to use the scanner to analyze two example messages: one with benign code and another with insecure code.","sidebar":"tutorialsSidebar"},"tutorials/prompt-guard-scanner-tutorial":{"id":"tutorials/prompt-guard-scanner-tutorial","title":"Prompt Guard Scanner Tutorial","description":"Welcome to the Prompt Guard Scanner tutorial! Here, we\'ll walk through the demopromptguard_scanner.py script from the examples to understand how the Prompt Guard Scanner works. The Prompt Guard Scanner is a lightweight, fast, and effective tool for detecting direct prompt injection attempts using a BERT-style classifier. This script will guide you through the process of setting up the firewall, configuring the scanner, and testing it with some example inputs.","sidebar":"tutorialsSidebar"},"tutorials/regex-scanner-tutorial":{"id":"tutorials/regex-scanner-tutorial","title":"Prompt Regex Scanner Tutorial","description":"In this tutorial, we\'ll break down the code in demoregexscanner.py from the examples to dive into using regular expressions to scan for harmful messages.","sidebar":"tutorialsSidebar"},"tutorials/standalone-agent-llamafirewall-tutorial":{"id":"tutorials/standalone-agent-llamafirewall-tutorial","title":"Notebook: Standalone Agent with LlamaFirewall","description":"This demo showcases a standalone agent implementation that integrates LlamaFirewall for security scanning. The agent can interact with users through a console interface, perform web searches, and fetch URL content while ensuring security through LlamaFirewall\'s scanning capabilities.","sidebar":"tutorialsSidebar"}}}}')}}]);